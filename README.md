# Репозиторий для сдачи домашних работ по дисциплине "Основы информационного поиска"

### Работы выполняются Хакимуллиным Рустемом и [Хазиевой Эльвирой](https://github.com/ElviraKhazieva) 11-901

### Запуск
1. Выполнить команду `python -m venv venv` (создание виртуального окружения)
2. Выполнить команду `venv\Scripts\activate` (активация виртуального окружения)
3. Выполнить команду `pip install -r requirements.txt` (установка нужных библиотек)
4. Выполнить команду `python web_crawler.py` (запуск скрипта)

#### Задание №1

Задание:

1. Скачать минимум 100 текстовых страниц с помощью краулера из предварительно подготовленного списка

Замечание:

- список страниц, сайтов можно найти в интернете
- каждая страница должна содержать текст (ссылки на js, css файлы недопустимы)
- язык текста должен быть одинаков для всех страниц

2. Записать каждую страницу в текстовый файл ("выкачка")

Замечание:

- очищать выкачку от html разметки НЕ надо(выкачиваем вместе с разметкой )

3. Создать файл index.txt в котором хранится номер файла и ссылка на страницу

Для оценки выполнения задания прислать:

- ссылку на гитхаб с репозиторием, в котором размещен код краулера
- архив с выкаченными страницами
- index.txt
